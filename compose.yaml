services:
  llm:
    image: "docker.io/ollama/ollama"
    volumes:
      - ollama_data:/root/.ollama
    entrypoint: ["/usr/bin/bash", "-c", "/bin/ollama serve & sleep 5; ollama pull qwen2:0.5b; wait"]

  app:
    build: ./app
    image: "docker.io/ptrusr/rofl-x402-docs:latest@sha256:503a20e60705222537f5b984cbc1b9e9a956832c9835dbb7511d3e6833d87e8b"
    platform: linux/amd64
    ports:
      - "4021:4021"
    annotations:
      net.oasis.proxy.ports.4021.custom_domain: summary.updev.si
    environment:
      - ADDRESS=${ADDRESS:-0x492F9757240365621fA03fbcee80f3eA72b98d15}
      - X402_NETWORK=${X402_NETWORK:-base-sepolia}
      - X402_PRICE=${X402_PRICE:-$0.001}
      - OLLAMA_HOST=http://llm:11434
    depends_on:
      - llm

volumes:
  ollama_data:
